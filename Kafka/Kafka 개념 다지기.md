# Kafka 개념 다지기

> 위 포스팅은 https://www.youtube.com/watch?v=0Ssx7jJJADI 유튜브 1 ~ 4편 을 참고하여 작성한 글 입니다.

<br>

## Kafka 조금 아는 척하기
> https://kafka.apache.org/

#### 기본 구조
![img.png](img/img.png) <br>

### 주키퍼 클러스터(앙상블)
- 카프카 클러스터 관리

### 카프카 클러스터
- 메시지를 저장하는 저장소이다
- 1개의 카프카 클러스터는 여러개의 브로커로 구성이 된다 -> 기본이 3개 <br>
- 카프카 클러스터에 있는 브로커는 각각의 서버라고 생각하면 된다 ex) port:9091, port:9092, port:9093 <br>
- 이 카프카 클러스터를 관리하기 위해서 Zookeeper 가 필요하게 된다 <br>
- Zookeeper 안에 카프카 클러스터와 관련된 정보가 기록이되고 관리가 된다 <br>

<br>

### Producer
- 카프카 클러스터에 메세지(이벤트)를 보내는 곳을 Producer 라고 함.
- 이 메시지를 카프카에 넣는 역할을 한다.
  - 메시지를 저장할 때 어떤 '**토픽**'에 저장해줘 라고 요청을 하게 된다.

### Consumer
- 메시지(이벤트)를 카프카에서 읽어오는 역할을 한다.
- 어떤 '**토픽**'에서 메시지를 읽어올래? 라는 역할을 한다.

프로듀서와 컨슈머는 토픽을 기준으로 메시지를 주고 받는다 <br>


### 토픽과 파티션
- **토픽**은 메시지를 구분하는 단위
  - ex) 파일 시스템의 폴더와 유사
- 한 개의 토픽은 한 개 이상의 파티션으로 구성
  - 파티션은 메시지를 저장하는 물리적인 파일

즉 토픽안에 파티션이 들어있다 <br>

![img_1.png](img/img_1.png) <br>

### 파티션과 오프셋, 메시지 순서
파티션은 append-only(추가만 가능한) 파일이다 <br>
- 각 메시지 저장 위치를 **offset** 이라고 한다
- 프로듀서가 넣는 메시지는 파티션의 맨 뒤에 추가한다 ex) Stack 느낌.
- 컨슈머는 오프셋 기준으로 메시지를 '**순서대로 읽는다**'.
- 메시지는 삭제되지 않음(설정에 따라 일정 시간이 지난 뒤 삭제 가능)

즉 한 파티션 내에서만 메시지 순서 보장 <br>
ex) 컨슈머가 파티션의 3번 오프셋 부터 읽어줘 하면 3번 이후 메시지만 읽고(3,4,5,6) 그전 메시지는 읽을 수 없다 <br>

### 여러 파티션과 프로듀서
![img_2.png](img/img_2.png) <br>
- 프로듀서는 라운드 로빈(돌아가면서 저장) 또는 키(해쉬)로 파티션 선택
  - 같은 키를 갖는 메시지는 같은 파티션에 저장 -> 같은 키는 순서 유지


- 컨슈머는 컨슈머 그룹에 속한다.
- 한 개 파티션은 컨슈머그룹의 한 개 컨슈머만 연결 가능
  - 즉 컨슈머 그룹에 속한 컨슈머들은 한 파티션을 공유할 수 없음
  - 한 컨슈머그룹 기준으로 파티션의 메시지는 순서대로 처리


### 성능
- 파티션 파일은 OS 페이지캐시 사용
  - 파티션에 대한 파일 IO 를 메모리에서 처리
  - 서버에서 페이지캐시를 카프카만 사용해야 성능에 유리
- Zero Copy
  - 디스크 버퍼에서 네트워크 버퍼로 직접 데이터 복사
- 컨슈머 추적을 위해 브로커가 하는 일이 비교적 단순
  - 메시지 필터, 메시지 재전송과 같은 일은 브로커가 하지 않음
    - 프로듀서, 컨슈머가 직접 해야함
  - 브로커는 컨슈머와 파티션 간 매핑 관리

- 묶어서 보내기, 묶어섭 받기(batch)
  - 프로듀서: 일정 크기만큼 메시지를 모아서 전송 가능
  - 컨슈머: 최소 크기만큼 메시지를 모아서 조회 가능
- 낱개 처리보다 처리량 증가
![img_3.png](img/img_3.png) <br>

- 처리량 증대(확장)이 쉬움
  - 1개 장비의 용량 한계? -> 브로커 추가, 파티션 추가
  - 컨슈머가 느리다? -> 컨슈머 추가(+파티션 추가)


### 레플리카 - 복제 -> 고가용성 처리
- 레플리카: 파티션의 복제본
  - 복제수 만큼 파티션의 복제본이 각 브로커에 생긴다
- 리더와 팔로와로 구성
  - 프로듀서와 컨슈머는 리더를 통해서만 메시지 처리
  - 팔로워는 리더로부터 복제
- 장애 대응
  - 리더가 속한 브로커 장애시 다른 팔로워가 리더가 됨


## Kafka - Producer
```java
// config 설정 spring -> application.yml
Properties prop = new Properties();
prop.put("bootstrap.servers","kafka-01:9092,kakfa-02:9093,kafka-03:9094");
prop.put("key.serializer","----StringSerializer");
prop.put("value.serializer","----StringSerializer");

KafkaProducer<Integer,String> producer = new KafkaProducer<>(prop);

producer.send(new ProducerRecord<>("topicName","key","value"));
producer.send(new ProducerRecord<>("topicName","value"));

producer.close();
```


































비동기식 소켓 통신시 다중서버로 서비스되고있을때, 
실제 POS 클라이언트와 커넥션이 맺어진 서버와, 
결제 결과 수신 ILK -> 큐뱅으로 전달받는 서버가 다를때 POS Endpoint와 connection된 서버를 찾기 위해서 카프카를 통해서 "ILK에서 응답왔다!"는 메세지를 서버 전체에 던지는것이고, 
모든 서버는 카프카가 발송하는 메세지를 수신 대기하고있는 상태로, 
이때 메세지를 수신한 서버들이 자기와 결제를 시도한 POS 클라이언트가 연결되어있는지를 체크하고 연결되어있는 서버는 POS에 응답을 내려주고 끝, 
나머지 서버는 나랑 연결된것이 없으니 메세지를 무시한다. 
예외적으로 모든 서버가 연결된 POS클라이언트를 확인하지 못하면 에러로 처리한다.